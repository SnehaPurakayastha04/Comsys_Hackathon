{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubX_4vAZU7vv"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ STEP 1: Install & Import\n",
        "!pip install scikit-learn pandas matplotlib seaborn --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# ‚úÖ STEP 2: Load CSVs\n",
        "df_train = pd.read_csv('/content/train_verification_results.csv')\n",
        "df_val = pd.read_csv('/content/val_verification_results.csv')\n",
        "\n",
        "# ‚úÖ STEP 3: Metric Function\n",
        "def evaluate(df, dataset_name='Dataset'):\n",
        "    y_true = df['label'].tolist()\n",
        "    best_thresh = 0.5\n",
        "    best_f1 = 0\n",
        "\n",
        "    # Threshold Tuning\n",
        "    for thresh in np.arange(0.3, 0.8, 0.01):\n",
        "        preds = [1 if s >= thresh else 0 for s in df['similarity']]\n",
        "        f1 = f1_score(y_true, preds)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thresh = thresh\n",
        "\n",
        "    # Final Evaluation\n",
        "    y_pred = [1 if s >= best_thresh else 0 for s in df['similarity']]\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "    # Print Metrics\n",
        "    print(f\"\\nüìä Evaluation on {dataset_name}:\")\n",
        "    print(f\"üîç Best Threshold: {best_thresh:.2f}\")\n",
        "    print(f\"Accuracy : {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall   : {rec:.4f}\")\n",
        "    print(f\"F1-Score : {f1:.4f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    labels = ['Negative (0)', 'Positive (1)']\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f'{dataset_name} Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "\n",
        "# ‚úÖ STEP 4: Run for Train and Val\n",
        "evaluate(df_train, dataset_name='Train Set')\n",
        "evaluate(df_val, dataset_name='Validation Set')\n",
        "\n",
        "torch.save(model.state_dict(), 'facenet_vggface2.pth')"
      ]
    }
  ]
}
