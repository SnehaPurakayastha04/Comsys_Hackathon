{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL2kzkTOUCf1"
      },
      "outputs": [],
      "source": [
        "# ✅ STEP 1: Install Required Libraries\n",
        "!pip install torch torchvision facenet-pytorch scikit-learn matplotlib pandas --quiet\n",
        "\n",
        "# ✅ STEP 2: Import Libraries\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageEnhance\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
        "from torchvision import transforms\n",
        "import random\n",
        "\n",
        "# ✅ STEP 3: Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "mtcnn = MTCNN(image_size=160, margin=10, device=device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "SIMILARITY_THRESHOLD = 0.75  # Initial threshold\n",
        "\n",
        "# ✅ STEP 4: Augmented Embedding Function with MTCNN\n",
        "@torch.no_grad()\n",
        "def get_augmented_embeddings(img_path, n_augments=3):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    aligned = mtcnn(img)\n",
        "    if aligned is None:\n",
        "        return None\n",
        "\n",
        "    variants = [aligned.cpu()]\n",
        "    for _ in range(n_augments):\n",
        "        aug_img = img.copy()\n",
        "        aug_img = ImageEnhance.Brightness(aug_img).enhance(np.random.uniform(0.8, 1.2))\n",
        "        aug_img = ImageEnhance.Contrast(aug_img).enhance(np.random.uniform(0.8, 1.2))\n",
        "        if np.random.rand() > 0.5:\n",
        "            aug_img = aug_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        aligned_aug = mtcnn(aug_img)\n",
        "        if aligned_aug is not None:\n",
        "            variants.append(aligned_aug.cpu())\n",
        "\n",
        "    embeddings = []\n",
        "    for v in variants:\n",
        "        v = v.unsqueeze(0).to(device)\n",
        "        emb = model(v).cpu().detach().numpy().flatten()\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    return np.mean(embeddings, axis=0)\n",
        "\n",
        "# ✅ STEP 5: Verification Function for Folder-Based Distortion with Optional Negatives\n",
        "def verify_from_folder(folder_path, save_csv_path, use_negatives=False, negatives_per_sample=3):\n",
        "    results = []\n",
        "    person_list = os.listdir(folder_path)\n",
        "\n",
        "    for person_id in tqdm(person_list, desc=f\"Processing {folder_path}\"):\n",
        "        person_dir = os.path.join(folder_path, person_id)\n",
        "        ref_img_path = os.path.join(person_dir, f\"{person_id}.jpg\")\n",
        "        distortion_folder = os.path.join(person_dir, \"distortion\")\n",
        "\n",
        "        if not os.path.exists(ref_img_path) or not os.path.isdir(distortion_folder):\n",
        "            continue\n",
        "\n",
        "        ref_embedding = get_augmented_embeddings(ref_img_path)\n",
        "        if ref_embedding is None:\n",
        "            continue\n",
        "\n",
        "        for distorted_img_name in os.listdir(distortion_folder):\n",
        "            distorted_img_path = os.path.join(distortion_folder, distorted_img_name)\n",
        "            distorted_embedding = get_augmented_embeddings(distorted_img_path)\n",
        "            if distorted_embedding is None:\n",
        "                continue\n",
        "\n",
        "            similarity = cosine_similarity([ref_embedding], [distorted_embedding])[0][0]\n",
        "            results.append({\n",
        "                'person_id': person_id,\n",
        "                'distorted_img': distorted_img_name,\n",
        "                'reference_id': person_id,\n",
        "                'similarity': similarity,\n",
        "                'label': 1\n",
        "            })\n",
        "\n",
        "            if use_negatives:\n",
        "                other_people = [p for p in person_list if p != person_id]\n",
        "                random.shuffle(other_people)\n",
        "                for neg_id in other_people[:negatives_per_sample]:\n",
        "                    neg_ref_path = os.path.join(folder_path, neg_id, f\"{neg_id}.jpg\")\n",
        "                    if os.path.exists(neg_ref_path):\n",
        "                        neg_embedding = get_augmented_embeddings(neg_ref_path)\n",
        "                        if neg_embedding is not None:\n",
        "                            sim_neg = cosine_similarity([neg_embedding], [distorted_embedding])[0][0]\n",
        "                            results.append({\n",
        "                                'person_id': person_id,\n",
        "                                'distorted_img': distorted_img_name,\n",
        "                                'reference_id': neg_id,\n",
        "                                'similarity': sim_neg,\n",
        "                                'label': 0\n",
        "                            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(save_csv_path, index=False)\n",
        "    print(f\"✅ Saved results to {save_csv_path}\")\n",
        "    return df\n",
        "\n",
        "# ✅ STEP 6: Run for Train & Val with Negatives\n",
        "train_dir = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/train'\n",
        "val_dir = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/val'\n",
        "\n",
        "df_train = verify_from_folder(train_dir, '/content/train_verification_results.csv', use_negatives=True)\n",
        "df_val = verify_from_folder(val_dir, '/content/val_verification_results.csv', use_negatives=True)\n",
        "\n",
        "# ✅ STEP 7: Threshold Tuning on Validation Set\n",
        "y_true = df_val['label'].tolist()\n",
        "best_thresh = 0.5\n",
        "best_f1 = 0\n",
        "\n",
        "for thresh in np.arange(0.3, 0.8, 0.01):\n",
        "    preds = [1 if s >= thresh else 0 for s in df_val['similarity']]\n",
        "    f1 = f1_score(y_true, preds)\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = thresh\n",
        "\n",
        "print(f\"\\n🔍 Best Threshold: {best_thresh:.2f} → F1: {best_f1:.4f}\")\n",
        "\n",
        "# ✅ STEP 8: Final Evaluation with Best Threshold\n",
        "y_pred = [1 if s >= best_thresh else 0 for s in df_val['similarity']]\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred)\n",
        "rec = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "print(\"\\n📊 Evaluation on Validation Set:\")\n",
        "print(f\"Accuracy : {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall   : {rec:.4f}\")\n",
        "print(f\"F1-Score : {f1:.4f}\")\n"
      ]
    }
  ]
}