{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AshAew06UwmH"
      },
      "outputs": [],
      "source": [
        "# Install Required Libraries\n",
        "!pip install torch torchvision facenet-pytorch scikit-learn matplotlib pandas --quiet\n",
        "\n",
        "# Import Libraries\n",
        "import os, random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image, ImageEnhance\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
        "\n",
        "# Setup Model and Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
        "mtcnn = MTCNN(image_size=160, margin=10, device=device)\n",
        "\n",
        "# Defining Embedding Function with augmentations\n",
        "# This function generates multiple augmented versions of an image, extracts embeddings,\n",
        "# and returns their average to improve robustness to image distortions\n"
        "@torch.no_grad()\n",
        "def get_augmented_embeddings(img_path, n_augments=3):\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    aligned = mtcnn(img)\n",
        "    if aligned is None:\n",
        "        return None\n",
        "\n",
        "    variants = [aligned.cpu()]\n",
        "    for _ in range(n_augments):\n",
        "        aug_img = img.copy()\n",
        "        aug_img = ImageEnhance.Brightness(aug_img).enhance(np.random.uniform(0.8, 1.2))\n",
        "        aug_img = ImageEnhance.Contrast(aug_img).enhance(np.random.uniform(0.8, 1.2))\n",
        "        if np.random.rand() > 0.5:\n",
        "            aug_img = aug_img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        aligned_aug = mtcnn(aug_img)\n",
        "        if aligned_aug is not None:\n",
        "            variants.append(aligned_aug.cpu())\n",
        "\n",
        "    embeddings = []\n",
        "    for v in variants:\n",
        "        v = v.unsqueeze(0).to(device)\n",
        "        emb = model(v).cpu().numpy().flatten()\n",
        "        embeddings.append(emb)\n",
        "\n",
        "    return np.mean(embeddings, axis=0)\n",
        "\n",
        "# Defining Verification Function\n",
        "# This function performs face verification by comparing reference images with distorted versions.\n"
        "# It also adds negative pairs to help train binary classification model.\n"
        "def verify_from_folder(folder_path, save_csv_path, use_negatives=True, negatives_per_sample=3):\n",
        "    results = []\n",
        "    person_list = os.listdir(folder_path)\n",
        "\n",
        "    for person_id in tqdm(person_list, desc=f\"Processing {folder_path}\"):\n",
        "        person_dir = os.path.join(folder_path, person_id)\n",
        "        ref_img_path = os.path.join(person_dir, f\"{person_id}.jpg\")\n",
        "        distortion_folder = os.path.join(person_dir, \"distortion\")\n",
        "\n",
        "        if not os.path.exists(ref_img_path) or not os.path.isdir(distortion_folder):\n",
        "            continue\n",
        "\n",
        "        ref_embedding = get_augmented_embeddings(ref_img_path)\n",
        "        if ref_embedding is None:\n",
        "            continue\n",
        "\n",
        "        for distorted_img_name in os.listdir(distortion_folder):\n",
        "            distorted_img_path = os.path.join(distortion_folder, distorted_img_name)\n",
        "            distorted_embedding = get_augmented_embeddings(distorted_img_path)\n",
        "            if distorted_embedding is None:\n",
        "                continue\n",
        "\n",
        "            similarity = cosine_similarity([ref_embedding], [distorted_embedding])[0][0]\n",
        "            results.append({\n",
        "                'person_id': person_id,\n",
        "                'distorted_img': distorted_img_name,\n",
        "                'reference_id': person_id,\n",
        "                'similarity': similarity,\n",
        "                'label': 1\n",
        "            })\n",
        "\n",
        "            if use_negatives:\n",
        "                other_people = [p for p in person_list if p != person_id]\n",
        "                random.shuffle(other_people)\n",
        "                for neg_id in other_people[:negatives_per_sample]:\n",
        "                    neg_ref_path = os.path.join(folder_path, neg_id, f\"{neg_id}.jpg\")\n",
        "                    if os.path.exists(neg_ref_path):\n",
        "                        neg_embedding = get_augmented_embeddings(neg_ref_path)\n",
        "                        if neg_embedding is not None:\n",
        "                            sim_neg = cosine_similarity([neg_embedding], [distorted_embedding])[0][0]\n",
        "                            results.append({\n",
        "                                'person_id': person_id,\n",
        "                                'distorted_img': distorted_img_name,\n",
        "                                'reference_id': neg_id,\n",
        "                                'similarity': sim_neg,\n",
        "                                'label': 0\n",
        "                            })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(save_csv_path, index=False)\n",
        "    print(f\"Saved results to {save_csv_path}\")\n",
        "    return df\n",
        "\n",
        "# Run the verification on Train and Validation sets\n",
        "train_dir = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/train'\n",
        "val_dir = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/val'\n",
        "\n",
        "df_train = verify_from_folder(train_dir, '/content/train_verification_results.csv')\n",
        "df_val = verify_from_folder(val_dir, '/content/val_verification_results.csv')\n"
      ]
    }
  ]
}
